{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huggingface transformers basics \n",
    "\n",
    "### customizing pretrained model\n",
    "\n",
    "General scheme for leveraging a pretrained model on a downstream task is Loading a model weight and modifying its architecture.\n",
    "\n",
    "허깅페이스 허브에서는 모델의 사전훈련 가중치를 다운받을 수 있고,  \n",
    "허깅페이스 라이브러리로 훈련 및 추론을 할 때는 모델 선택 등 많은 부분을 자동화되어 있어 편리하다.    \n",
    "  \n",
    "하지만 모델 설계 변경,\n",
    "classification task 등을 위해 classification head 부착 후 훈련 등,  \n",
    "모델 가중치 로드 뿐 아니라 모델을 직접 변경하여야 할 때가 있다.\n",
    "  \n",
    "목표: RoBERTa 모델에 허깅페이스 모델 체크포인트(훈련된 가중치)를 로드 뒤  \n",
    "모델 일부 (뒷부분 헤드)을 변경한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model\n",
    "\n",
    "transformers의 AutoModel은 모델 체크포인트가 훈련되었던 모델 구조를 편리하게 로드한다.  \n",
    "체크포인트로부터 모델을 로드하면 바로 DebertaV2Model 오브젝트가 로드된다.  \n",
    "해당 오브젝트의 doc 설명(DebertaV2Model)의 설명에 따르면  \n",
    "DebertaV2Model은 추가 헤드 없이 raw hidden-state를 출력하는 DeBERTa 구조이다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSdpaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebertaV2Model(\n",
      "  (embeddings): DebertaV2Embeddings(\n",
      "    (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    (dropout): StableDropout()\n",
      "  )\n",
      "  (encoder): DebertaV2Encoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-5): 6 x DebertaV2Layer(\n",
      "        (attention): DebertaV2Attention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (pos_dropout): StableDropout()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaV2SelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaV2Intermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaV2Output(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (rel_embeddings): Embedding(512, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"google-bert/bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.41.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.41.1\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "DebertaV2Config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.41.1\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In detail information of DebertaV2Config and   \\ndifferent objects list(model/tokenizer/etc) of Huggingface DeBERTa-v2 model   \\nthat is applicable for different learning scenario >   \\n[doc]DeBERTa-v2 https://huggingface.co/docs/transformers/model_doc/deberta-v2#transformers.DebertaV2Config'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "print(model)\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-small\")\n",
    "print(model)\n",
    "# for additional detail usage > [doc]auto https://huggingface.co/docs/transformers/model_doc/auto\n",
    "\n",
    "from transformers import AutoConfig, AutoModel\n",
    "NewModelConfig = AutoConfig.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "print(NewModelConfig)\n",
    "\n",
    "# AutoConfig은 \"microsoft/deberta-v3-small\" checkpoint에 맞는 DebertaV2Config 오브젝트를 초기화하고 해당 Config을 자동으로 로드함\n",
    "NewModelConfig = AutoConfig.from_pretrained(\"microsoft/deberta-v3-small\")\n",
    "print(NewModelConfig) \n",
    "\n",
    "# DebertaV2Config 오브젝트를 명시적으로 지정후 체크포인트 명시해서 로드시 같은 Config으로 되어 있음\n",
    "from transformers import DebertaV2Config\n",
    "NewDebertaV2ModelConfig = DebertaV2Config.from_pretrained(\"microsoft/deberta-v3-small\")\n",
    "print(NewDebertaV2ModelConfig) \n",
    "\n",
    "'''In detail information of DebertaV2Config and   \n",
    "different objects list(model/tokenizer/etc) of Huggingface DeBERTa-v2 model   \n",
    "that is applicable for different learning scenario >   \n",
    "[doc]DeBERTa-v2 https://huggingface.co/docs/transformers/model_doc/deberta-v2#transformers.DebertaV2Config'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto task model for a specific task\n",
    "\n",
    "AutoModel는 모델 체크포인트 정보만 있으면 모델을 로드하지만 목적하는 태스크에 맞는 헤드 등 직접 작성해야 함  \n",
    "자주 쓰는 태스크의 경우(e.g. sequence classification)\n",
    "태스크에 맞는 Auto 클래스를 체크포인트와 함께 지정하면   \n",
    "허깅페이스에서 미리 작성해둔 태스크용 모델을 자동 선택하기 때문에    \n",
    "목적하는 태스크에 맞는 헤드 등을 직접 작성할 필요 없어 편리하게 이용 가능  \n",
    "(e.g. sequence classification은 AutoModel 대신 AutoModelForSequenceClassification 이용)   \n",
    "\n",
    "\n",
    "파이토치 모델이고 구조는 모두 공개되어 있으므로, 이 이후 모델 구조를 직접 자유롭게 고치는 것도 가능\n",
    "\n",
    "사용법은 AutoModel과 동일  \n",
    "\"configuration\" 지정하면 시작부터 태스크용 모델 훈련  \n",
    "\"체크포인트\" 형식으로 지정하면 가중치가 적용된 태스크용 모델을 돌려줌  \n",
    "체크포인트 경우 from_pretrained 를 이용해 체크포인트만 지정하면 됨  \n",
    "\n",
    "(e.g. 시퀀스 데이터 분류 태스크의 경우 AutoModelForSequenceClassification을 임포트후  \n",
    " Debertav2 모델의 어떤 체크포인트를 불러오면 \n",
    "Debertav2 모델의 sequence classification 모델을 따로 돌려줌)\n",
    "\n",
    "모든 Auto 클래스는 문서 확인. 예시 문서 AutoModelForSequenceClassification\n",
    "[doc] AutoModelForSequenceClassification : \n",
    "https://huggingface.co/docs/transformers/v4.41.2/en/model_doc/auto#transformers.AutoModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebertaV2ForSequenceClassification(\n",
      "  (deberta): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pooler): ContextPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): StableDropout()\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): StableDropout()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-small\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  AutoTokenizer를 사용한 토크나이저 불러오기\n",
    "DebertaV2Tokenizer를 자동으로 로드한다.(이 노트북 스코프에서는 토크나이저를 자세히 다루지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979863f701af4ebcbb2cc900b6fe2e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed03847d02448a299b01589b6c1a11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebertaV2Tokenizer(name_or_path='microsoft/deberta-v3-small', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t128000: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43585b4df5f41e9b593eeebd70a4fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9088249a022345229a4d3ca0706d0342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8e7104420f42c091cff827b5f2acfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizerFast(name_or_path='google-bert/bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoTokenizer\n",
    "\n",
    "# https://discuss.huggingface.co/t/error-with-new-tokenizers-urgent/2847/3\n",
    "\n",
    "# v4.0.0 이후 AutoTokenizer 및 파이프라인은 fast (rust) tokenizer를 기본값으로 사용함\n",
    "# [github]huggingface transformers https://github.com/huggingface/transformers/releases/tag/v4.0.0\n",
    "# newTokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-small\")\n",
    "# print(newTokenizer)\n",
    "newTokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-small\", use_fast=False)\n",
    "print(newTokenizer)\n",
    "\n",
    "\n",
    "newTokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "print(newTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 146, 1821, 2520, 17947, 102]\n",
      "['I', 'am', 'talking', 'potato']\n"
     ]
    }
   ],
   "source": [
    "text = \"I am talking potato\"\n",
    "\n",
    "print(newTokenizer.encode(text))\n",
    "print(newTokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
